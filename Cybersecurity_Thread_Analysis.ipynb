{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrYMpKiqpoDO",
        "outputId": "a0c6c45f-7f35-4342-9cd0-3c1278333ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Schema:\n",
            "root\n",
            " |-- Timestamp: timestamp (nullable = true)\n",
            " |-- IP_Address: string (nullable = true)\n",
            " |-- Request_Type: string (nullable = true)\n",
            " |-- Status_Code: integer (nullable = true)\n",
            " |-- Anomaly_Flag: integer (nullable = true)\n",
            " |-- User_Agent: string (nullable = true)\n",
            " |-- Session_ID: integer (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            "\n",
            "Sample Data:\n",
            "+-------------------+--------------+------------+-----------+------------+----------+----------+--------+\n",
            "|Timestamp          |IP_Address    |Request_Type|Status_Code|Anomaly_Flag|User_Agent|Session_ID|Location|\n",
            "+-------------------+--------------+------------+-----------+------------+----------+----------+--------+\n",
            "|2023-01-01 00:00:00|202.118.116.11|GET         |403        |0           |Edge      |4835      |Brazil  |\n",
            "|2023-01-01 00:01:00|38.30.40.178  |DELETE      |301        |0           |Bot       |3176      |China   |\n",
            "|2023-01-01 00:02:00|209.5.148.15  |POST        |500        |0           |Opera     |4312      |China   |\n",
            "|2023-01-01 00:03:00|211.116.60.71 |GET         |301        |0           |Bot       |1003      |France  |\n",
            "|2023-01-01 00:04:00|170.166.36.145|POST        |404        |0           |Firefox   |1428      |Germany |\n",
            "+-------------------+--------------+------------+-----------+------------+----------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Unique values in the 'Anomaly_Flag' column:\n",
            "+------------+\n",
            "|Anomaly_Flag|\n",
            "+------------+\n",
            "|           1|\n",
            "|           0|\n",
            "+------------+\n",
            "\n",
            "High-Risk IP Addresses:\n",
            "+---------------+-----+\n",
            "|     IP_Address|count|\n",
            "+---------------+-----+\n",
            "|     15.6.62.53|    2|\n",
            "|  151.199.52.16|    1|\n",
            "|111.249.110.248|    1|\n",
            "|164.213.229.165|    1|\n",
            "| 225.210.23.216|    1|\n",
            "|  203.28.140.21|    1|\n",
            "| 27.124.124.185|    1|\n",
            "| 108.131.81.194|    1|\n",
            "|  21.179.233.66|    1|\n",
            "|  38.244.241.84|    1|\n",
            "|  131.120.69.67|    1|\n",
            "|233.189.249.249|    1|\n",
            "|   70.33.26.223|    1|\n",
            "| 119.199.221.61|    1|\n",
            "|160.112.240.228|    1|\n",
            "|  28.100.200.85|    1|\n",
            "| 32.251.120.224|    1|\n",
            "| 98.249.146.184|    1|\n",
            "|  136.60.95.130|    1|\n",
            "|195.186.182.153|    1|\n",
            "+---------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf, when\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Cybersecurity Threat Detection\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Specify the local file path to your dataset\n",
        "file_path = \"/content/drive/My Drive/advanced_cybersecurity_data.csv\" # Replace with the actual file path\n",
        "\n",
        "# Load the dataset with header=True\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Display schema\n",
        "print(\"Dataset Schema:\")\n",
        "df.printSchema()\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Sample Data:\")\n",
        "df.show(5, truncate=False)\n",
        "\n",
        "# Inspect unique values in the \"Anomaly_Flag\" column\n",
        "print(\"Unique values in the 'Anomaly_Flag' column:\")\n",
        "df.select(\"Anomaly_Flag\").distinct().show()\n",
        "\n",
        "# Handle non-numeric values in the \"Anomaly_Flag\" column\n",
        "df = df.withColumn(\n",
        "    \"Anomaly_Flag\",\n",
        "    when(col(\"Anomaly_Flag\") == \"True\", 1)\n",
        "    .when(col(\"Anomaly_Flag\") == \"False\", 0)\n",
        "    .otherwise(col(\"Anomaly_Flag\"))\n",
        ")\n",
        "\n",
        "# Cast the \"Anomaly_Flag\" column to integer type\n",
        "df = df.withColumn(\"Anomaly_Flag\", col(\"Anomaly_Flag\").cast(IntegerType()))\n",
        "\n",
        "# Define a function to classify network requests\n",
        "def classify_request(anomaly_flag):\n",
        "    if anomaly_flag == 1:  # Assuming 1 indicates suspicious activity\n",
        "        return \"suspicious\"\n",
        "    else:\n",
        "        return \"normal\"\n",
        "\n",
        "# Register the function as a UDF\n",
        "classify_request_udf = udf(classify_request, StringType())\n",
        "\n",
        "# Add a new column to classify requests\n",
        "df = df.withColumn(\"request_class\", classify_request_udf(col(\"Anomaly_Flag\")))\n",
        "\n",
        "# Filter suspicious requests\n",
        "suspicious_requests = df.filter(col(\"request_class\") == \"suspicious\")\n",
        "\n",
        "# Group by IP address and count suspicious requests\n",
        "high_risk_ips = suspicious_requests.groupBy(\"IP_Address\").count().orderBy(\"count\", ascending=False)\n",
        "\n",
        "# Show high-risk IPs\n",
        "print(\"High-Risk IP Addresses:\")\n",
        "high_risk_ips.show()\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    }
  ]
}